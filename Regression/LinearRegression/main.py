from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))


from generate_data import generate_data
from explore_data import explore_data
from visualize_data import visualize_data
from preprocess_data import preprocess_data
from train_model import train_model
from evaluate_model import evaluate_model
from visualize_results import visualize_results
"""
ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹
"""
print("\n" + "=" * 60)
print("ğŸ  çº¿æ€§å›å½’å®Œæ•´é¡¹ç›®")
print("=" * 60)

# 1. ç”Ÿæˆæ•°æ®
print("\næ­£åœ¨ç”Ÿæˆæ•°æ®...")
df = generate_data(n_samples=200, noise=10, random_state=42)

# 2. æ•°æ®æ¢ç´¢
correlation = explore_data(df)

# 3. æ•°æ®å¯è§†åŒ–
print("\n" + "=" * 60)
print("ğŸ“Š æ•°æ®å¯è§†åŒ–")
print("=" * 60)
visualize_data(df)

# 4. æ•°æ®é¢„å¤„ç†
X_train, X_test, y_train, y_test, scaler, X_train_orig, X_test_orig = preprocess_data(df, test_size=0.2, random_state=42)

# 5. æ¨¡å‹è®­ç»ƒ
model = train_model(X_train, y_train, feature_names=X_train_orig.columns.tolist())

# 6. æ¨¡å‹è¯„ä¼°
y_train_pred, y_test_pred = evaluate_model(
    model, X_train, X_test, y_train, y_test
)

# 7. ç»“æœå¯è§†åŒ–
visualize_results(y_train, y_train_pred, y_test, y_test_pred,
                    X_test_orig, X_train_orig.columns)